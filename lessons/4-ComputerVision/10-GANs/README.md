# Generative Adversarial Networks

<!-- In the previous section, we learned about **generative models**: models that can generate new images similar to the ones in the training dataset. VAE was a good example of a generative model. -->
在上一节中，我们了解了**generative models生成模型**：可以生成与训练数据集中的图像相似的新图像的模型。VAE 是生成模型的一个很好的例子。

## [Pre-lecture quiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/110)

<!-- However, if we try to generate something really meaningful, like a painting at reasonable resolution, with VAE, we will see that training does not converge well. For this use case, we should learn about another architecture specifically targeted at generative models - **Generative Adversarial Networks**, or GANs. -->
然而，如果我们尝试使用 VAE 生成一些真正有意义的东西，例如具有合理分辨率的绘画，我们会发现训练不能很好地收敛。对于这个用例，我们应该了解另一种专门针对生成模型的架构 -生成对抗网络**Generative Adversarial Networks**（GAN）。

<!-- The main idea of a GAN is to have two neural networks that will be trained against each other: -->
GAN 的主要思想是拥有两个相互训练的神经网络：

<img src="images/gan_architecture.png" width="70%"/>

> Image by [Dmitry Soshnikov](http://soshnikov.com)

<!-- > ✅ A little vocabulary:
> * **Generator** is a network that takes some random vector, and produces the image as a result
> * **Discriminator** is a network that takes an image, and it should tell whether it is a real image (from training dataset), or it was generated by a generator. It is essentially an image classifier. -->

> ✅ 一些词汇：
> * **Generator** 生成器是一个网络，它采用一些随机向量，并生成图像作为结果。
> * **Discriminator**鉴别器是一个获取图像的网络，它应该判断它是真实图像（来自训练数据集）还是由生成器生成。它本质上是一个图像分类器。

### Discriminator

<!-- The architecture of discriminator does not differ from an ordinary image classification network. In the simplest case it can be fully-connected classifier, but most probably it will be a [convolutional network](../07-ConvNets/README.md). -->
鉴别器的架构与普通图像分类网络没有什么不同。在最简单的情况下，它可以是全连接分类器，但最有可能的是卷积网络[convolutional network](../07-ConvNets/README.md)。

<!-- > ✅ A GAN based on convolutional networks is called a [DCGAN](https://arxiv.org/pdf/1511.06434.pdf) -->

> ✅ 基于卷积网络的 GAN 称为[DCGAN](https://arxiv.org/pdf/1511.06434.pdf)

<!-- A CNN discriminator consists of the following layers: several convolutions+poolings (with decreasing spatial size) and, one-or-more fully-connected layers to get "feature vector", final binary classifier. -->
CNN 判别器由以下层组成：多个卷积+池化（空间尺寸逐渐减小）以及一个或多个全连接层以获得“特征向量”，即最终的二元分类器。

<!-- > ✅ A 'pooling' in this context is a technique that reduces the size of the image. "Pooling layers reduce the dimensions of data by combining the outputs of neuron clusters at one layer into a single neuron in the next layer." - [source](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers) -->

✅ 在这种情况下，“池化”是一种减小图像大小的技术。“池化层通过将一层神经元簇的输出组合到下一层的单个神经元中来减少数据的维度。” -[来源](https://wikipedia.org/wiki/Convolutional_neural_network#Pooling_layers)

### Generator

<!-- A Generator is slightly more tricky. You can consider it to be a reversed discriminator. Starting from a latent vector (in place of a feature vector), it has a fully-connected layer to convert it into the required size/shape, followed by deconvolutions+upscaling. This is similar to *decoder* part of [autoencoder](../09-Autoencoders/README.md). -->
生成器稍微棘手一些。您可以将其视为反向判别器。从潜在向量（代替特征向量）开始，它有一个全连接层将其转换为所需的大小/形状，然后进行反卷积+放大。这类似于自动编码器的解码器[autoencoder](../09-Autoencoders/README.md).部分。

<!-- > ✅ Because the convolution layer is implemented as a linear filter traversing the image, deconvolution is essentially similar to convolution, and can be implemented using the same layer logic. -->
> ✅ 因为卷积层被实现为遍历图像的线性滤波器，所以反卷积本质上与卷积类似，并且可以使用相同的层逻辑来实现。

<img src="images/gan_arch_detail.png" width="70%"/>

> Image by [Dmitry Soshnikov](http://soshnikov.com)

### Training the GAN

<!-- GANs are called **adversarial** because there is a constant competition between the generator and the discriminator. During this competition, both generator and discriminator improve, thus the network learns to produce better and better pictures. -->
GAN 被称为**对抗性的**，因为生成器和判别器之间存在着持续的竞争。在这场比赛中，生成器和判别器都得到了改进，因此网络学会了生成越来越好的图片。


The training happens in two stages:

<!-- * **Training the discriminator**. This task is pretty straightforward: we generate a batch of images by the generator, labeling them 0, which stands for fake image, and taking a batch of images from the input dataset (with label 1, real image). We obtain some *discriminator loss*, and perform backprop. -->
* **Training the discriminator训练鉴别器**。这个任务非常简单：我们通过生成器生成一批图像，将它们标记为 0（代表假图像），并从输入数据集中获取一批图像（标签为 1，真实图像）。我们获得一些判别器损失，并执行反向传播。
<!-- * **Training the generator**. This is slightly more tricky, because we do not know the expected output for the generator directly. We take the whole GAN network consisting of a generator followed by discriminator, feed it with some random vectors, and expect the result to be 1 (corresponding to real images). We then freeze the parameters of the discriminator (we do not want it to be trained at this step), and perform the backprop. -->
* **Training the generator生成器**。这稍微有点棘手，因为我们不直接知道生成器的预期输出。我们采用由生成器和判别器组成的整个 GAN 网络，向其提供一些随机向量，并期望结果为 1（对应于真实图像）。然后我们冻结鉴别器的参数（我们不希望在这一步对其进行训练），并执行反向传播。

<!-- During this process, both the generator and the discriminator losses are not going down significantly. In the ideal situation, they should oscillate, corresponding to both networks improving their performance. -->
在此过程中，生成器和鉴别器的损耗都没有显着下降。在理想情况下，它们应该振荡，对应于两个网络都提高了性能。

## ✍️ Exercises: GANs

* [GAN Notebook in TensorFlow/Keras](GANTF.ipynb)
* [GAN Notebook in PyTorch](GANPyTorch.ipynb)

### Problems with GAN training

<!-- GANs are known to be especially difficult to train. Here are a few problems: -->
众所周知，GAN 的训练特别困难。这里有几个问题：

<!-- * **Mode Collapse**. By this term we mean that the generator learns to produce one successful image that tricks the generator, and not a variety of different images. -->
* **Mode Collapse模式崩溃**. 通过这个术语，我们的意思是生成器学习生成一个成功的图像来欺骗生成器，而不是各种不同的图像。
<!-- * **Sensitivity to hyperparameters**. Often you can see that a GAN does not converge at all, and then suddenly decreases in the learning rate leading to convergence. -->
* **Sensitivity to hyperparameters对超参数的敏感性**.通常你会看到 GAN 根本不收敛，然后学习率突然降低导致收敛。

<!-- * Keeping a **balance** between the generator and the discriminator. In many cases discriminator loss can drop to zero relatively quickly, which results in the generator being unable to train further. To overcome this, we can try setting different learning rates for the generator and discriminator, or skip discriminator training if the loss is already too low. -->
* 在生成器和鉴别器之间保持**balance平衡**。在许多情况下，鉴别器损失可以相对较快地降至零，这导致生成器无法进一步训练。为了克服这个问题，我们可以尝试为生成器和判别器设置不同的学习率，或者如果损失已经太低则跳过判别器训练。
<!-- * Training for **high resolution**. Reflecting the same problem as with autoencoders, this problem is triggered because reconstructing too many layers of convolutional network leads to artifacts. This problem is typically solved with so-called **progressive growing**, when first a few layers are trained on low-res images, and then layers are "unblocked" or added. Another solution would be adding extra connections between layers and training several resolutions at once - see this [Multi-Scale Gradient GANs paper](https://arxiv.org/abs/1903.06048) for details. -->
* **高分辨率**训练。反映了与自动编码器相同的问题，触发该问题的原因是重构太多层的卷积网络会导致伪影。这个问题通常通过所谓的**渐进式增长**来解决，首先在低分辨率图像上训练几层，然后“解锁”或添加层。另一种解决方案是在层之间添加额外的连接并同时训练多个分辨率 -有关详细信息，请参阅这篇多尺度梯度 GAN[Multi-Scale Gradient GANs paper](https://arxiv.org/abs/1903.06048) 论文。

## Style Transfer

<!-- GANs is a great way to generate artistic images. Another interesting technique is so-called **style transfer**, which takes one **content image**, and re-draws it in a different style, applying filters from **style image**.  -->
GAN 是生成艺术图像的好方法。另一种有趣的技术是所谓的**风格转移**，它采用一个**内容图像**，并以不同的风格重新绘制它，应用**风格图像**的过滤器。

The way it works is the following:
<!-- * We start with a random noise image (or with a content image, but for the sake of understanding it is easier to start from random noise) -->
* 我们从随机噪声图像开始（或从内容图像开始，但为了理解，从随机噪声开始更容易）
<!-- * Our goal would be to create such an image, that would be close to both content image and style image. This would be determined by two loss functions:
   - **Content loss** is computed based on the features extracted by the CNN at some layers from current image and content image
   - **Style loss** is computed between current image and style image in a clever way using Gram matrices (more details in the [example notebook](StyleTransfer.ipynb)) -->

* 我们的目标是创建这样一个图像，既接近内容图像又接近风格图像。这将由两个损失函数决定：
   - **Content loss内容损失** 是根据 CNN 在某些层从当前图像和内容图像中提取的特征来计算的。
   - **Style loss** 使用 Gram 矩阵以巧妙的方式在当前图像和风格图像之间计算风格损失（更多详细信息请参阅示例笔记本）。

<!-- * To make the image smoother and remove noise, we also introduce **Variation loss**, which computes average distance between neighboring pixels -->
* 为了使图像更平滑并消除噪声，我们还引入了**变化损失**，它计算相邻像素之间的平均距离
<!-- * The main optimization loop adjusts current image using gradient descent (or some other optimization algorithm) to minimize the total loss, which is a weighted sum of all three losses.  -->
* 主优化循环使用梯度下降（或其他一些优化算法）调整当前图像，以最小化总损失，总损失是所有三个损失的加权和。

## ✍️ Example: [Style Transfer](StyleTransfer.ipynb)

## [Post-lecture quiz](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/210)

## Conclusion

<!-- In this lesson, you learned about GANS and how to train them. You also learned about the special challenges that this type of Neural Network can face, and some strategies on how to move past them. -->
在本课程中，您了解了 GANS 以及如何训练它们。您还了解了此类神经网络可能面临的特殊挑战，以及如何克服这些挑战的一些策略。

## 🚀 Challenge

Run through the [Style Transfer notebook](StyleTransfer.ipynb) using your own images.

## Review & Self Study

For reference, read more about GANs in these resources:

* Marco Pasini, [10 Lessons I Learned Training GANs for one Year](https://towardsdatascience.com/10-lessons-i-learned-training-generative-adversarial-networks-gans-for-a-year-c9071159628)
* [StyleGAN](https://en.wikipedia.org/wiki/StyleGAN), a *de facto* GAN architecture to consider
* [Creating Generative Art using GANs on Azure ML](https://soshnikov.com/scienceart/creating-generative-art-using-gan-on-azureml/)

## Assignment

Revisit one of the two notebooks associated to this lesson and retrain the GAN on your own images. What can you create?